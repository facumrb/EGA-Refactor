# **De la Célula al Código - Entendiendo EGA-Refactor**
#### **Objetivo General:** Comprender cómo se puede usar un algoritmo inspirado en la evolución de Darwin (Algoritmo Genético) con una red de genes simulada por computadora.

## **Módulo 1: Introducción a la Biología de Sistemas Computacional**

### **Tema 1: Modelización de Redes de Regulación Génica mediante Ecuaciones Diferenciales Ordinarias.**
*   **Del Genotipo al Fenotipo - El Problema Central de la Regulación**
El genoma, idéntico en casi todas nuestras células, puede ser visto como un repertorio estático de componentes potenciales. Esto significa que todas las células de un organismo multicelular (como nosotros) comparten el mismo genoma, es decir, el mismo conjunto de ADN. Por otra parte, el genotipo es el conjunto de genes (información genética) que codifica las características de un organismo; es el conjunto específico de variantes genéticas que un individuo posee. Se refiere a cómo está configurado su genoma en ciertos loci (lugares). Sin embargo, la biología es dinámica. El fenotipo celular (la manifestación observable del genotipo: su forma, función y comportamiento) es un estado emergente que resulta de la interacción compleja y temporalmente variable de estos componentes (está influenciado por el ambiente). La pregunta fundamental es: ¿cuáles son los principios de diseño que gobiernan la transición del genotipo estático (secuencia de ADN que no cambia en el transcurso de la vida de una célula u organismo) al fenotipo dinámico (cambio con el tiempo y el entorno debido a factores como temperatura, nutrición, estrés, y señales químicas que pueden activar o silenciar genes)? La respuesta reside en la regulación de la expresión génica. La expresión génica es el proceso mediante el cual la información contenida en un gen se utiliza para sintetizar un producto funcional, como una proteína o un ARN funcional. Una proteína es una macromolécula formada por una cadena de aminoácidos, que se pliega en una estructura tridimensional específica para cumplir una función; y un ARN funcional es un tipo de ARN (Ácido Ribonucleico) que no se traduce en proteína, pero cumple funciones directamente en la célula.
*   **El Dogma Central como Flujo de Información**
El Dogma Central (ADN → ARN → Proteína) no debe ser visto como un proceso lineal y unidireccional, sino como un flujo de información regulado. La transcripción y la traducción son procesos estocásticos y altamente controlados, cuyas tasas determinan la concentración de cada proteína en la célula -sí, las células están formadas por proteínas pero no exclusivamente-. Son estas concentraciones de proteínas, el proteoma , las que en última instancia definen el estado celular. Nuestro objetivo es modelar la dinámica de este proteoma. El archivo `evaluator_toy.py` no es más que un intento de encapsular esta dinámica en un sistema computable. Representa nuestro 'sistema biológico virtual' o in silico. ¿Cómo lo hace? `evaluator_toy.py` simula la concentración de estas proteínas (llamadas aquí "factores de transcripción"). El objetivo del proyecto es entender qué parámetros producen la cantidad correcta de estas proteínas.
### **Tema 2: Redes de Regulación Génica (GRN).**
*   **Redes de Regulación Génica como Sistemas Dinámicos**
Los genes no trabajan solos. Se encienden y apagan unos a otros en una red compleja, como un circuito eléctrico. Los "factores de transcripción" son proteínas especiales que actúan como interruptores, activando o reprimiendo otros genes. Los genes no operan en el vacío. La expresión de un gen es frecuentemente regulada por los productos de otros genes, principalmente por factores de transcripción. Estas interacciones definen una Red de Regulación Génica (GRN, por sus siglas en inglés). Matemáticamente, podemos representar una GRN como un grafo dirigido, donde los nodos son los genes y las aristas representan las interacciones regulatorias (activación o represión). El "corazón" del problema biológico está en `evaluator_toy.py`, que modela una pequeña red de 3 genes que interactúan entre sí. La simulación intenta replicar cómo la cantidad de una proteína afecta a la producción de las otras.
*   **La Dinámica del Sistema**
Una GRN es un sistema dinámico. Su 'estado' en cualquier instante de tiempo t puede ser definido por un vector de las concentraciones de sus proteínas. La pregunta clave es: dado un estado en el tiempo t, ¿cuál será el estado en t + Δt ? La respuesta está en las ecuaciones que gobiernan la tasa de cambio de cada componente del sistema. El modelo dentro de `evaluator_toy.py` implementa una GRN minimalista. La simplicidad es intencional; nos permite estudiar los principios de la dinámica de redes sin la complejidad de un sistema biológico real. Es un arquetipo, un modelo canónico de una red regulatoria.
### **Tema 3: ¿Qué es un Modelo Computacional?**
*   **Formalismo Matemático - Ecuaciones Diferenciales Ordinarias (EDOs)**
Un modelo es una simplificación de la realidad que nos ayuda a entenderla. Usamos las matemáticas para describir procesos biológicos. Por ejemplo, podemos escribir una ecuación que describa cómo cambia la cantidad de una proteína con el tiempo. Todo el archivo `evaluator_toy.py` es un **modelo matemático** de la red génica. La función `_ode_system` define las ecuaciones que gobiernan el comportamiento de nuestro sistema biológico simplificado: calcula la "tasa de cambio" (`dydt`) para cada una de las 3 proteínas basándose en sus parámetros de producción (`prod`), degradación (`deg`) e interacción (`inter`). Para describir la evolución temporal del estado de nuestro sistema, recurrimos al lenguaje del cálculo: las Ecuaciones Diferenciales Ordinarias (EDOs). Una EDO nos permite expresar la tasa de cambio instantánea de una variable (la concentración de una proteína, d[P]/dt) en función del estado actual del sistema.
*   **Anatomía de la Ecuación**
La forma más simple de una EDO para la concentración de una proteína P es: **d[P]/dt = Tasa de Producción - Tasa de Degradación**
    * La Tasa de Degradación a menudo se modela como un proceso de primer orden, proporcional a la concentración actual: γ * [P].Se asume que la proteína se degrada de forma proporcional a su concentración actual. γ es la constante de degradación (1/t).
    * La Tasa de Producción es el término más interesante. En ausencia de regulación, es una constante basal β. β es una constante de producción (concentración/tiempo). Sin embargo, la regulación por parte de factores de transcripción (activadores A, represores R) modula este término. A y R son las concentraciones de los activadores y represores, respectivamente. Funciones como la de Michaelis-Menten o, más comúnmente, la función de Hill, se utilizan para modelar la naturaleza sigmoidal y cooperativa de estas interacciones: Producción Regulada = β * (A^n / (K^n + A^n)), donde n es la cooperación de Hill (número de factores de transcripción que deben estar activos para activar la proteína), K es la concentración del activador A necesaria para alcanzar la mitad de la producción máxima, y "sigmoidal" es la forma en que una célula responde gradualmente a una señal, pero con un comportamiento de umbral: Poca señal → poca respuesta, Señal suficiente → respuesta rápida, y Mucha señal → respuesta saturada.
    
    Observe la función `_ode_system` en `evaluator_toy.py`. Es precisamente la implementación de un sistema de EDOs acopladas. Cada línea dentro de esa función calcula el d[P]/dt para una proteína del sistema. Los params que recibe la función (producción, degradación, interacción) son los coeficientes de estas ecuaciones (β, γ, K, n). Estos son los parámetros que definen la dinámica específica de nuestra red.
*   **El Problema Inverso - De la Dinámica a los Parámetros**
    En muchos escenarios, tenemos datos experimentales sobre el comportamiento de un sistema (ej. una serie temporal de la expresión de un gen), pero desconocemos los parámetros cinéticos exactos que generan esa dinámica. Este es el problema inverso o de estimación de parámetros. El objetivo es encontrar los valores de los parámetros (β, γ, K, n) que mejor se ajusten a los datos experimentales. Para resolverlo, definimos una función objetivo (o de coste), J(θ) , donde θ es el vector de parámetros de nuestro modelo. Esta función cuantifica la discrepancia entre la salida de nuestra simulación (simulate(θ)) y los datos experimentales u objetivo deseado (target). Una métrica común es el error cuadrático medio (MSE).
    J(θ) = Σ ( y_simulado(t, θ) - y_objetivo(t) )²
    Donde:
    * Σ representa la suma sobre todos los puntos de tiempo (t) en nuestros datos experimentales.
    * y_simulado(t, θ) es la concentración de la proteína simulada para el tiempo t y los parámetros θ.
    * y_objetivo(t) es la concentración experimental de la proteína para el tiempo t.
    * t es cada punto de tiempo en nuestros datos experimentales.

    El objetivo es encontrar el conjunto de parámetros θ* que minimice esta función: θ* = argmin J(θ)
    Donde:
    * argmin representa el valor de θ que minimiza la función J(θ).
    * θ* es el vector de parámetros que mejor se ajusta a los datos experimentales.
    * J(θ*) es el valor mínimo de la función objetivo, que indica la mejor discrepancia entre la simulación y los datos experimentales.

    En resumen, el objetivo es encontrar los parámetros θ* que minimicen la discrepancia entre la simulación y los datos experimentales. 
    
    La función evaluate en `evaluator_toy.py` es nuestra función objetivo. Toma un conjunto de parámetros, llama a `simulate` para resolver numéricamente las EDOs y obtener la trayectoria del sistema, y luego la compara con el `target`, devolviendo un valor de 'fitness' (que en este caso, es análogo a un coste: menor es mejor). El espacio de posibles parámetros θ es vasto y a menudo de alta dimensionalidad, y la topología de la función de coste J(θ) puede ser compleja y multimodal. Por lo tanto, no podemos simplemente resolver para θ* analíticamente. Necesitamos un algoritmo de búsqueda robusto para explorar este espacio de parámetros. Esto nos lleva directamente a nuestro próximo tema: los algoritmos evolutivos como método de optimización estocástica global.

## **Módulo 2: La Solución Inspirada en la Naturaleza: Algoritmos Genéticos**
### **Tema 1: El "Fitness": ¿Qué tan buena es una solución?**
*   **Del Problema Inverso al Paisaje de Fitness** 
    En biología, "fitness" (aptitud) se refiere a la capacidad de un ser vivo para sobrevivir y reproducirse. En nuestro modelo, el "fitness" es una puntuación que nos dice qué tan cerca está nuestra simulación de un resultado deseado (`target`). Un fitness más bajo significa que nuestra simulación se parece más al objetivo. La función `evaluate` en `evaluator_toy.py` calcula este fitness, pero lo hace a través de una función de coste multifacética que va más allá de una simple distancia:
    - **Distancia Euclidiana (Norma L2):** El componente principal del coste es `np.linalg.norm(y_final - self.target)`, que mide la distancia directa en el espacio de estados entre el punto final de la simulación y el objetivo. Es la medida más intuitiva de "qué tan cerca" estamos.
    - **Penalización por Complejidad (Regularización L1):** La función de coste añade un término `0.001 * np.sum(np.abs(params))`. Esta es una técnica de regularización que penaliza a los individuos con parámetros de gran magnitud. En un contexto biológico, esto se alinea con el principio de parsimonia: favorece soluciones más simples y robustas, que dependen de interacciones menos "extremas", evitando el sobreajuste del modelo a nuestro `target` específico.
    - **Heurística de Recompensa (`reached_reward`):** Se incluye una pequeña "recompensa" (un coste negativo) si la trayectoria de la simulación se acerca al objetivo en *cualquier* punto, no solo al final. Esto crea gradientes artificiales en el paisaje de fitness, ayudando a guiar al algoritmo en la dirección correcta, especialmente en las primeras etapas de la búsqueda.

El objetivo del algoritmo es, por lo tanto, encontrar los parámetros que minimicen esta función de coste compuesta, equilibrando la cercanía al objetivo con la simplicidad del modelo. En la conclusión del Módulo 1, establecimos nuestro problema central: el problema inverso. Disponemos de un modelo de sistema dinámico, nuestra red de regulación génica en `evaluator_toy.py`, y un comportamiento objetivo (`target`). La tarea consiste en encontrar el vector de parámetros θ* que minimiza una función de coste J(θ), la cual cuantifica la discrepancia entre la dinámica simulada y la objetivo.
    θ* = argmin J(θ)
    Debemos conceptualizar la función J(θ) como un paisaje de fitness (o, más precisamente, un paisaje de coste). Este es un hiperplano donde cada punto corresponde a un vector de parámetros θ y su altitud viene dada por el valor de J(θ). Nuestro objetivo es encontrar el punto más bajo (el mínimo global) en este paisaje. Este es el punto que nos da los mejores parámetros para nuestro modelo. En otras palabras, estamos buscando el vector θ* que minimice la función de coste J(θ). En términos más simples, estamos buscando los parámetros que mejor se ajusten a los datos experimentales.
    Ahora, considera la naturaleza de este paisaje. Dada la no linealidad de las EDOs que modelan las interacciones génicas, este paisaje es complejo, multimodal (con múltiples mínimos locales) y de alta dimensionalidad. Los métodos de optimización basados en gradiente, aunque eficientes, corren un alto riesgo de quedar atrapados en mínimos locales. Resolver para θ* analíticamente es, en la mayoría de los casos, intratable. Por lo tanto, necesitamos un método de búsqueda que sea robusto, capaz de explorar eficazmente este vasto espacio de parámetros y que no dependa de la información del gradiente. Aquí es donde entran en juego las heurísticas de optimización global, y específicamente, los Algoritmos Genéticos.

### **Tema 2: La Teoría de la Evolución de Darwin.**
*   **El Paradigma de la Computación Evolutiva** 
    El Algoritmo Genético, formalizado por John Holland, no es simplemente una analogía con la evolución darwiniana; es un marco computacional robusto. Su poder reside en la manipulación de una población de soluciones candidatas en paralelo, equilibrando dos fuerzas fundamentales: la explotación de las buenas soluciones encontradas y la exploración de nuevas regiones del espacio de búsqueda.
    Vamos a formalizar la analogía con nuestro proyecto:
    Genotipo y Fenotipo:
    * El Genotipo es la codificación de una solución. En nuestro caso, es el vector de parámetros de punto flotante θ = (prod_params, deg_params, inter_params). En `ega_core.py`, esto está encapsulado en la clase Individual, específicamente en su atributo `self.params`.
    * El Fenotipo es la expresión del genotipo en el entorno del problema. Corresponde a la trayectoria temporal `y_simulado(t, θ)` que resulta de resolver las EDOs con un genotipo θ particular. Este es el resultado de la función simulate en `evaluator_toy.py`.
    La Función de Fitness:
    * El Fitness es una medida cuantitativa de la calidad de un fenotipo. En optimización, está directamente relacionado con la función objetivo. Dado que nuestro J(θ) es una función de coste (menor es mejor), podemos definir el fitness como 1 / (1 + J(θ)) o, como se hace en este proyecto por simplicidad, tratar el coste directamente como un valor a minimizar. La función evaluate en `evaluator_toy.py` es precisamente nuestra J(θ), calculando el error cuadrático medio y una penalización por complejidad.
*   **Anatomía de un Algoritmo Genético Elitista (EGA)**
    Ahora, diseccionemos la implementación en `ega_core.py`. Este archivo implementa un Algoritmo Genético Elitista (EGA), una variante que garantiza la no degradación de la mejor solución encontrada a lo largo de las generaciones.
    **Inicialización de la Población:**
    * El proceso comienza creando una population de N Individual(es). Cada individuo es inicializado con un genotipo θ muestreado aleatoriamente dentro de unos límites predefinidos (bounds en `config.yaml`). Esta es una siembra inicial en el paisaje de fitness para comenzar la búsqueda.
    **Ciclo Evolutivo (El bucle run):**
    El algoritmo itera a través de un número definido de `generations`.
        * a) Evaluación: Para cada individuo en la población, se calcula su fitness llamando a la función evaluate. Esto es computacionalmente la parte más costosa. Para manejar esta carga y hacer el algoritmo eficiente y robusto, la implementación en `ega_core.py` incluye optimizaciones cruciales:
            - **Evaluación en Paralelo:** Utiliza el módulo `multiprocessing.Pool` de Python para distribuir la evaluación de la población entre múltiples núcleos de CPU. Esto paraleliza el paso más lento del algoritmo, reduciendo drásticamente el tiempo de ejecución total.
            - **Caché de Evaluaciones:** Mantiene un diccionario (`self.cache`) que almacena el fitness de cada individuo ya evaluado. Si un individuo reaparece en una generación posterior (por elitismo, por ejemplo), su fitness se recupera instantáneamente del caché, evitando la costosa resolución del sistema de EDOs.
            - **Timeout por Evaluación:** Cada evaluación individual se ejecuta con un `timeout`. Si un conjunto de parámetros provoca que la simulación de las EDOs sea inestable, demasiado lenta o no converja, el proceso se interrumpe y se le asigna un fitness "infinito" (muy pobre). Esto evita que individuos problemáticos detengan todo el proceso evolutivo.
        * b) Elitismo: Se identifican los k mejores individuos de la población actual (definido por `elite_size`). Estos individuos se copian directamente a la siguiente generación, sin modificación. Esto asegura la convergencia monotónica del mejor fitness de la población.
        * c) Selección: Para crear el resto de la nueva generación, debemos seleccionar a los "padres". `ega_core.py` implementa la selección por torneo (`tournament_selection`). Se seleccionan aleatoriamente m individuos de la población y el de mejor fitness "gana" el torneo y es elegido como padre. Este método es eficiente y permite ajustar la presión selectiva (la probabilidad de que el mejor individuo sea seleccionado) variando el tamaño del torneo.
        * d) Operadores Genéticos - Creación de Descendencia:
            * Cruzamiento (Crossover): Se seleccionan dos padres y se aplica el operador de cruzamiento para generar descendencia, combinando su material genético. La implementación utiliza `blx_alpha_crossover` (Blend Crossover). Este es un operador aritmético diseñado para genotipos de valor real. Para cada gen (parámetro), el valor del hijo se elige aleatoriamente en un rango que se extiende más allá de los valores de los padres, controlado por el parámetro `alpha`. Esto permite una exploración más audaz que un simple promedio.
            * Mutación: Después del cruzamiento, cada gen del nuevo individuo tiene una pequeña probabilidad (`mutation_rate`) de ser alterado. La `gaussian_mutation` suma un valor aleatorio extraído de una distribución gaussiana con media cero y una desviación estándar específica. Este operador es crucial para mantener la diversidad genética en la población, prevenir la convergencia prematura a un mínimo local y permitir el ajuste fino de los parámetros.
        * e) Reemplazo: La nueva población, compuesta por la élite y la descendencia, reemplaza a la población anterior, y el ciclo vuelve a comenzar.

    Hay variación en una población, los individuos compiten por recursos, los mejor adaptados (con mayor "fitness") sobreviven y dejan más descendencia (selección natural). Con el tiempo, la población evoluciona. El archivo `ega_core.py` es una implementación de estas ideas en código. Es un "Algoritmo Genético Elitista" (EGA). En resumen, el `ega_core.py` no es solo una simulación de la evolución; es un motor de optimización sofisticado. Orquesta una búsqueda poblacional y paralela que navega por el complejo paisaje de parámetros de nuestro modelo biológico. Al final del proceso, el "mejor individuo" no es solo una curiosidad computacional; representa el vector de parámetros θ* que, según nuestro modelo y nuestra función de coste, es la hipótesis más plausible para explicar el comportamiento dinámico objetivo. Por lo tanto, el Algoritmo Genético actúa como un puente entre el modelo teórico (`evaluator_toy.py`) y los datos (el `target`), permitiéndonos hacer inferencias sobre los parámetros cinéticos subyacentes de un sistema biológico. Es una herramienta fundamental en la caja de herramientas de cualquier biólogo de sistemas computacional.

    **- **Una Nota sobre la Reproducibilidad Científica:** Un pilar de cualquier experimento computacional es la reproducibilidad. El `EGA-Refactor` garantiza esto a través del parámetro `seed` en `config.yaml`. Esta "semilla" inicializa todos los generadores de números aleatorios (usados en la creación de la población inicial, selección, cruzamiento y mutación). Al usar la misma semilla, se asegura que una ejecución del algoritmo producirá exactamente los mismos resultados, un requisito indispensable para la validación, depuración y comunicación de los hallazgos científicos.**

### **Tema 3: Traduciendo la Evolución a Código.**
*   **Individuo:** 
    Es un conjunto de parámetros (las tasas de producción, degradación, etc.). Representa una posible solución a nuestro problema biológico. (Clase `Individual` en `ega_core.py`).
*   **Población:** 
    Un grupo de muchos individuos diferentes, cada uno con sus propios parámetros. (La lista `self.population`).
*   **Fitness:** 
    La puntuación que obtiene cada individuo de la función `evaluate`.
*   **Selección (por Torneo):** 
    Se eligen al azar unos pocos individuos y el que tiene mejor fitness "gana" y pasa a reproducirse. Simula la "supervivencia del más apto". (Función `tournament_selection`).
*   **Cruzamiento (Crossover):** 
    Dos individuos "padres" combinan sus parámetros para crear un nuevo individuo "hijo", mezclando sus características. (Función `blx_alpha_crossover`).
*   **Mutación:** 
    Se introducen pequeños cambios aleatorios en los parámetros de un individuo. Esto genera nueva "variación" en la población. (Función `gaussian_mutation`).
*   **Elitismo:** 
    Los mejores individuos de una generación pasan directamente a la siguiente sin cambios, asegurando que no perdamos las mejores soluciones encontradas. (Parámetro `elite_size`).


## **Módulo 3: ¡Manos a la Obra! Ejecutando el Experimento**

### **Tema 1: Configurando el Experimento.**
*   **El `config.yaml` como Protocolo Experimental** 
En nuestro caso, el archivo config.yaml es nuestro protocolo experimental digital. No es una mera lista de parámetros, sino el manifiesto que dicta cada aspecto de nuestra simulación. La externalización de estos parámetros es una práctica fundamental en la ciencia computacional, ya que garantiza la reproducibilidad, flexibilidad y escalabilidad de nuestros hallazgos.
**Vamos a analizar el archivo `config.yaml`**
1.  Parámetros del Algoritmo Genético (Sección`ega`): Estos gobiernan el comportamiento de nuestro motor de optimización, el `ega_core.py`.
    * `populationSize`: El tamaño de nuestra población de soluciones candidatas. Una población más grande permite explorar el espacio de búsqueda más ampliamente, pero a un mayor costo computacional.
    * `generations`: El número de ciclos evolutivos. Define la duración del experimento. Más generaciones dan más tiempo al algoritmo para converger hacia una buena solución.
    * `crossover_rate` y `mutation_rate`: Son las fuerzas motrices de la evolución. El cruce (`crossover_rate`) promueve la explotación de soluciones prometedoras, mientras que la mutación (`mutation_rate`) fomenta la exploración de nuevas regiones del espacio de búsqueda, evitando estancamientos en óptimos locales.
    * `bounds`: Definen el espacio de búsqueda biológicamente plausible para los parámetros del modelo (`prod` , `deg` , `inter`). Es crucial establecer límites realistas para guiar al algoritmo de manera eficiente.
2.  Parámetros del Modelo Biológico (Sección `evaluator`): Estos configuran nuestro sistema biológico virtual, el `evaluator_toy.py`.
    * `t_span` y `dt`: Definen el horizonte temporal y la resolución de la simulación de la ODE, análogo a decidir por cuánto tiempo y con qué frecuencia tomamos muestras en un experimento de laboratorio.
    * `target`: Este es el corazón del problema. Representa la dinámica de expresión génica que deseamos replicar, nuestro "fenotipo objetivo". Podría provenir de datos experimentales previos o ser un comportamiento teórico que queremos alcanzar. La función de fitness en `evaluator_toy.py` medirá la distancia entre la simulación de cada individuo y este `target`.

El script `run_demo.py` actúa como el investigador principal: lee meticulosamente este protocolo (`config.yaml`) y lo utiliza para instruir tanto al algoritmo genético como al evaluador, asegurando que el experimento se lleve a cabo exactamente como fue diseñado.

### **Tema 2: Orquestación y Ejecución: `run_demo.py` como Director de Orquesta**
Si `config.yaml` es la partitura, `run_demo.py` es el director de orquesta. Es el script ejecutable que inicia, coordina y finaliza el experimento, asegurando que todos los componentes interactúen en la secuencia correcta.

El flujo de ejecución es el siguiente:
1. Carga del Protocolo: `run_demo.py` comienza cargando la configuración desde `config.yaml`.
2. Preparación del Laboratorio: Instancia el `ToyODEEvaluator` a partir de `evaluator_toy.py`, pasándole los parámetros del modelo. En este momento, nuestro laboratorio virtual está listo para simular trayectorias genéticas.
3. Creación del Motor Evolutivo: A continuación, instancia el EGA desde `ega_core.py`. De manera crucial, le pasa no solo sus propios hiperparámetros (tamaño de población, generaciones, etc.), sino también la instancia del evaluador (`ToyODEEvaluator`). Esta conexión es vital: el algoritmo genético ahora tiene un mecanismo para medir el "éxito" (fitness) de cada una de sus soluciones candidatas.
4. Inicio de la Evolución: Se invoca el método `ega.run()`. Aquí es donde la magia ocurre. Durante cientos de generaciones, el EGA gestionará el ciclo de vida de la población: evaluará cada individuo usando el evaluator, seleccionará a los mejores, los cruzará y los mutará, creando una nueva generación ligeramente más adaptada que la anterior.
5. Presentación de Resultados: Una vez completadas todas las generaciones, `run_demo.py` reporta el resultado final: los parámetros del mejor individuo encontrado y su valor de fitness. Este es el resultado de nuestro experimento.

### **Tema 3: El Gran Final: ¿Qué estamos buscando?**
*   **Interpretación de los Resultados** 
La ejecución del script no es el final, sino el comienzo del análisis científico. ¿Qué hemos encontrado?
1. El Objetivo Cumplido: El propósito de todo este proceso era encontrar un conjunto de parámetros (`prod`, `deg`, `inter`) que, al ser simulados en nuestro modelo de red génica (`evaluator_toy.py`), producen una dinámica temporal que se asemeja lo más posible a nuestro `target`. El "mejor individuo" que reporta `run_demo.py` es la hipótesis más plausible que el algoritmo ha podido encontrar.
2. Análisis Biológico: Los parámetros obtenidos deben ser interpretados en su contexto biológico. ¿Son los valores de producción y degradación consistentes con lo que sabemos sobre la estabilidad de estas proteínas? ¿La fuerza de interacción predicha tiene sentido biológico? Este es el punto donde la biología computacional se encuentra con la biología de sistemas.
3. Análisis de Convergencia: Al ejecutar `run_demo.py`, observamos la mejora del fitness generación tras generación. Una curva de fitness que se aplana indica que el algoritmo ha convergido. Si converge a un valor de fitness alto, podría significar que está atrapado en un óptimo local. En ese caso, deberíamos volver a nuestro protocolo (`config.yaml`) y considerar ajustar parámetros como la tasa de mutación o el tamaño de la población para fomentar una mayor exploración.
4. La Piedra Angular de la Ciencia: Reproducibilidad: Gracias al parámetro seed en `config.yaml` y a la arquitectura modular de nuestro código, otro investigador puede tomar nuestro proyecto, ejecutarlo con el mismo `config.yaml` y obtener exactamente los mismos resultados. Este es un pilar fundamental del método científico.
El objetivo final de todo el proyecto es usar el algoritmo genético (`ega_core.py`) para encontrar el conjunto de **parámetros** (genes del individuo) que, al ser usados en el modelo biológico (`evaluator_toy.py`), producen un resultado lo más parecido posible al **objetivo** (`target`).

Conclusión: Al ejecutar `run_demo.py`, vemos cómo el algoritmo, generación tras generación, va encontrando individuos con un fitness cada vez mejor, "evolucionando" una solución al problema de regulación génica.